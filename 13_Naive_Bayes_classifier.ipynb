{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8G_7lJPiqrJ"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "1\\. Describe in writing what an assumption is made when a naive Bayes classifier is created. Why the classifier is naive?\n",
        "\n",
        "2\\. Describe in writing what means maximum likelihood?\n",
        "\n",
        "3\\. Make a copy of a naive Bayes classifier that we used above to create a spam filter and try to improve its performance.\n",
        "Split the data set into training, validation and test data. Select the best model using the validation dataset and then compute your final score on the testing data. To improve the model for example the whole message content can be taken into account instead of the subject only. Also lengths of tokens that are taken into account can be varied. May be it would be interesting to split the messages into digramms: couples of words going one after another. And so on.\n",
        "\n",
        "4\\. Try to improve the Gaussian naive Bayes classifier. Split the data set into training, validation and test data. Select the best model using the validation dataset and then compute your final score on the testing data.\n",
        "\n",
        "5\\. Previously we discussed that in the most cases data must be standardized before creation of a machine learning model. Why it does not influences the performance of a Gaussian naive Bayes classifier?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. При создании наивного байесовского классификатора предполагается, что все признаки условно независимы от переменной класса. Это предположение \"наивное\", поскольку оно упрощает вычисление вероятности заданных признаков переменной класса, предполагая, что признаки независимы друг от друга. Однако редко это предположение верно для реальных данных, всегда есть какая-нибудь корелляция."
      ],
      "metadata": {
        "id": "3LtdErSkkMRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Метод максимального подобия — это метод, используемый в статистике для оценки параметров статистической модели, его цель — найти значения параметров модели, которые дадут максимум функции \"подобия\", которая, в свою очередь, является произведением функций плотности распределения вероятности для наблюдаемых данных."
      ],
      "metadata": {
        "id": "wz9Lq5QWlGvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. В случае гауссовского наивного байесовского классификатора нормализация данных не требуется и не оказывает влияния на производительность модели, потому что здесь мы не учитываем величину параметров, а работаем с распределениями (пдф) этих величин внутри каждого класса. Поскольку этот классификатор предполагает, что объекты следуют нормальному распределению и вычисляет среднее значение и стандартное отклонение каждого параметра внутри классов, в итоге масштаб не влияет на расчеты модели."
      ],
      "metadata": {
        "id": "1evtT9nNrAsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"In the _text2tokens method, the code now considers the entire text content without focusing only on the subject.\"\"\"\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import numpy as np\n",
        "import csv\n",
        "import requests\n",
        "from io import BytesIO, TextIOWrapper\n",
        "from zipfile import ZipFile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self, k, drop_short):\n",
        "        self.k = k\n",
        "        self.vocab = set()\n",
        "        self.token_in_spam = defaultdict(int)\n",
        "        self.token_in_ham = defaultdict(int)\n",
        "        self.pcond_spam = self.pcond_ham = None\n",
        "        self.spam_total = self.ham_total = 0\n",
        "        self.p_spam_total = self.p_ham_total = None\n",
        "        self.re_token = re.compile(r\"[a-z']+\")\n",
        "        self.drop_short = drop_short\n",
        "\n",
        "    def _text2tokens(self, text):\n",
        "        text_lower = text.lower()\n",
        "        all_tokens = self.re_token.findall(text_lower)\n",
        "        good_tokens = [tok for tok in all_tokens if len(tok) > self.drop_short]\n",
        "        return good_tokens\n",
        "\n",
        "    def fit(self, messages, labels):\n",
        "        for mes, lab in zip(messages, labels):\n",
        "            tokens = self._text2tokens(mes)\n",
        "            if lab == 'spam':\n",
        "                self.spam_total += 1\n",
        "                for token in tokens:\n",
        "                    self.token_in_spam[token] += 1\n",
        "            else:\n",
        "                self.ham_total += 1\n",
        "                for token in tokens:\n",
        "                    self.token_in_ham[token] += 1\n",
        "            self.vocab.update(tokens)\n",
        "        self.pcond_spam = defaultdict(int)\n",
        "        self.pcond_ham = defaultdict(int)\n",
        "        for token in self.vocab:\n",
        "            self.pcond_spam[token] = (self.token_in_spam[token] + self.k) / (self.spam_total + 2 * self.k)\n",
        "            self.pcond_ham[token] = (self.token_in_ham[token] + self.k) / (self.ham_total + 2 * self.k)\n",
        "        self.p_spam_total = self.spam_total / (self.spam_total + self.ham_total)\n",
        "        self.p_ham_total = 1 - self.p_spam_total\n",
        "\n",
        "    def predict(self, messages):\n",
        "        pred = []\n",
        "        for mes in messages:\n",
        "            message_tokens = self._text2tokens(mes)\n",
        "            log_sum_spam = np.log(self.p_spam_total)\n",
        "            log_sum_ham = np.log(self.p_ham_total)\n",
        "            for tok in self.vocab:\n",
        "                p_spam = self.pcond_spam[tok]\n",
        "                p_ham = self.pcond_ham[tok]\n",
        "                if tok not in message_tokens:\n",
        "                    p_spam = 1 - p_spam\n",
        "                    p_ham = 1 - p_ham\n",
        "                log_sum_spam += np.log(p_spam)\n",
        "                log_sum_ham += np.log(p_ham)\n",
        "            pred.append('spam' if log_sum_spam > log_sum_ham else 'ham')\n",
        "        return pred\n",
        "\n",
        "    def explore_vocab(self):\n",
        "        spam_words = []\n",
        "        for tok in self.vocab:\n",
        "            p_spam = self.pcond_spam[tok] * self.p_spam_total\n",
        "            p_ham = self.pcond_ham[tok] * self.p_ham_total\n",
        "            if p_spam > p_ham:\n",
        "                spam_words.append([tok, p_spam])\n",
        "\n",
        "        spam_words = sorted(spam_words, key=lambda x: -x[1])\n",
        "        words_only = [s[0] for s in spam_words]\n",
        "        return words_only\n",
        "\n",
        "\n",
        "def load_zipcsv_categorical(file_name):\n",
        "    \"\"\"Downloads zipped csv dataset from repo and return it as a nested list.\"\"\"\n",
        "    base_url = \"https://raw.githubusercontent.com/kupav/data-sc-intro/main/data/\"\n",
        "    web_data = requests.get(base_url + file_name)\n",
        "    assert web_data.status_code == 200\n",
        "    zf = ZipFile(BytesIO(web_data.content))\n",
        "    zipped_name = zf.namelist()[0]\n",
        "    print(f\"Download {file_name}, unzip {zipped_name}\")\n",
        "    with zf.open(zipped_name, 'r') as file:\n",
        "        reader = csv.reader(TextIOWrapper(file), delimiter=',')\n",
        "        data = []\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "    return data\n",
        "\n",
        "\n",
        "raw_data = load_zipcsv_categorical(\"spam_and_ham.zip\")\n",
        "data_lab = [row[1] for row in raw_data[1:]]\n",
        "data_mes = [row[2] for row in raw_data[1:]]\n",
        "p_test = 0.1\n",
        "n_test = round(p_test * len(data_lab))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_mes, data_lab, random_state=0,\n",
        "                                                    test_size=n_test, shuffle=True)\n",
        "nbc = NaiveBayes(k=1, drop_short=2)\n",
        "nbc.fit(X_train, y_train)\n",
        "y_pred = nbc.predict(X_test)\n",
        "acc = metrics.accuracy_score(y_test, y_pred)\n",
        "f1 = metrics.f1_score(y_test, y_pred, average='binary', pos_label='spam')\n",
        "print(f\"Accuracy = {acc:.4f}\")\n",
        "print(f\"F1-score = {f1:.4f}\")\n",
        "spam_words = nbc.explore_vocab()\n",
        "print(spam_words[:100])"
      ],
      "metadata": {
        "id": "vYMUHnesk32m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de3f2a9-dfac-4eb5-e299-3fd30bb58e61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download spam_and_ham.zip, unzip spam_ham_dataset.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-a6f06adef048>:64: RuntimeWarning: invalid value encountered in log\n",
            "  log_sum_ham += np.log(p_ham)\n",
            "<ipython-input-8-a6f06adef048>:63: RuntimeWarning: invalid value encountered in log\n",
            "  log_sum_spam += np.log(p_spam)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.7118\n",
            "F1-score = 0.0000\n",
            "['http', 'company', 'more', 'www', 'here', 'font', 'only', 'statements', 'email', 'nbsp', 'height', 'width', 'its', 'size', 'free', 'stock', 'within', 'pills', 'investment', 'money', 'inc', 'securities', 'align', 'computron', 'click', 'best', 'prices', 'looking', 'online', 'products', 'news', 'color', 'microsoft', 'net', 'face', 'windows', 'save', 'future', 'border', 'million', 'many', 'software', 'href', 'most', 'professional', 'link', 'internet', 'high', 'without', 'account', 'companies', 'market', 'info', 'world', 'international', 'viagra', 'such', 'adobe', 'src', 'act', 'reply', 'special', 'offer', 'stocks', 'low', 'cialis', 'remove', 'stop', 'section', 'advice', 'center', 'site', 'shares', 'home', 'own', 'results', 'visit', 'security', 'soft', 'buy', 'dollars', 'meds', 'performance', 'newsletter', 'style', 'full', 'family', 'prescription', 'even', 'top', 'quality', 'works', 'long', 'offers', 'limited', 'interest', 'bgcolor', 'pro', 'index', 'paliourg']\n"
          ]
        }
      ]
    }
  ]
}